# üîß FINAL SECURITY GROUP FIX - Zero Packet Loss

## Current Status
- ‚úÖ Master node: Running perfectly (Kubernetes v1.28.15)
- ‚ùå Worker nodes: Cannot connect due to security group restrictions
- ‚ùå Network: 100% packet loss between instances

## üéØ SOLUTION: Fix Security Groups in AWS Console

### Step 1: Open AWS Console
1. Go to: **https://console.aws.amazon.com/ec2/v2/home?region=eu-north-1#Instances:sort=instanceId**

### Step 2: Identify Your Instances
Look for these instances:
- **Master**: `ec2-51-20-43-244.eu-north-1.compute.amazonaws.com`
- **Worker-1**: `ec2-16-170-98-124.eu-north-1.compute.amazonaws.com`
- **Worker-2**: `ec2-51-21-255-93.eu-north-1.compute.amazonaws.com`

### Step 3: Fix Security Groups (CRITICAL)

**For EACH instance (Master, Worker-1, Worker-2):**

1. **Select the instance**
2. **Click on the Security Group link** (in the Security tab)
3. **Click "Edit inbound rules"**
4. **Click "Add rule"**
5. **Configure the rule:**
   - **Type**: All traffic
   - **Protocol**: All
   - **Port range**: All
   - **Source**: Custom
   - **Security group**: Select the **SAME security group** (the one attached to the instance)
6. **Click "Save rules"**

### Step 4: Alternative Approach (If Step 3 doesn't work)

If the above doesn't work, try this more permissive approach:

1. **Go to Security Groups** in AWS Console
2. **Find the security group** attached to your instances
3. **Add these specific rules:**

   **Rule 1:**
   - Type: All traffic
   - Protocol: All
   - Port range: All
   - Source: 21.32.12.0/22 (subnet CIDR)

   **Rule 2:**
   - Type: All ICMP - IPv4
   - Protocol: All
   - Port range: All
   - Source: 21.32.12.0/22

### Step 5: Test Connectivity

After fixing security groups, test connectivity:

```bash
# Test ping
ssh -i /home/ju-nine/Downloads/gis-openstack-m07-y25-ec2-principal20250729104020211200000003\(1\).pem ubuntu@ec2-16-170-98-124.eu-north-1.compute.amazonaws.com 'ping -c 5 21.32.12.44'

# Test port 6443
ssh -i /home/ju-nine/Downloads/gis-openstack-m07-y25-ec2-principal20250729104020211200000003\(1\).pem ubuntu@ec2-16-170-98-124.eu-north-1.compute.amazonaws.com 'timeout 5 bash -c "</dev/tcp/21.32.12.44/6443" && echo "‚úÖ Port 6443 reachable" || echo "‚ùå Port 6443 blocked"'
```

### Step 6: Join Worker Nodes

Once connectivity is working, join the worker nodes:

```bash
# Get join command
ssh -i /home/ju-nine/Downloads/gis-openstack-m07-y25-ec2-principal20250729104020211200000003\(1\).pem ubuntu@ec2-51-20-43-244.eu-north-1.compute.amazonaws.com 'sudo kubeadm token create --print-join-command'

# Join worker nodes
ssh -i /home/ju-nine/Downloads/gis-openstack-m07-y25-ec2-principal20250729104020211200000003\(1\).pem ubuntu@ec2-16-170-98-124.eu-north-1.compute.amazonaws.com 'sudo kubeadm join 21.32.12.44:6443 --token [TOKEN] --discovery-token-ca-cert-hash [HASH] --ignore-preflight-errors=all'

ssh -i /home/ju-nine/Downloads/gis-openstack-m07-y25-ec2-principal20250729104020211200000003\(1\).pem ubuntu@ec2-51-21-255-93.eu-north-1.compute.amazonaws.com 'sudo kubeadm join 21.32.12.44:6443 --token [TOKEN] --discovery-token-ca-cert-hash [HASH] --ignore-preflight-errors=all'
```

### Step 7: Verify Cluster

```bash
# Check nodes
ssh -i /home/ju-nine/Downloads/gis-openstack-m07-y25-ec2-principal20250729104020211200000003\(1\).pem ubuntu@ec2-51-20-43-244.eu-north-1.compute.amazonaws.com 'kubectl get nodes'

# Check pods
ssh -i /home/ju-nine/Downloads/gis-openstack-m07-y25-ec2-principal20250729104020211200000003\(1\).pem ubuntu@ec2-51-20-43-244.eu-north-1.compute.amazonaws.com 'kubectl get pods --all-namespaces'
```

## üö® IMPORTANT NOTES

1. **The issue is NOT with the instances** - they are working perfectly
2. **The issue is NOT with Kubernetes** - the master is running fine
3. **The issue is ONLY with AWS security groups** blocking internal traffic
4. **Once security groups are fixed, everything will work immediately**

## üéâ Expected Result

After fixing security groups:
- ‚úÖ 0% packet loss
- ‚úÖ Worker nodes can join the cluster
- ‚úÖ Full Kubernetes cluster operational
- ‚úÖ All pods running on all nodes

## üîç Troubleshooting

If you still have issues after fixing security groups:

1. **Check Network ACLs**: Go to VPC > Network ACLs
2. **Check Route Tables**: Go to VPC > Route Tables
3. **Check VPC settings**: Ensure instances are in the same VPC/subnet

The master node is ready and waiting - just fix the security groups and your cluster will be complete! 